{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73,90,75],\n",
    "                             [93,88,93],\n",
    "                             [89,91,90],\n",
    "                             [96,98,100],\n",
    "                             [73,66,70]])\n",
    "y_train = torch.FloatTensor([[152],[185],[180],[196],[142]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H(x) 계산  \n",
    "hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b   =>  x의 길이가 엄청나게 길다면 문제가 생김  \n",
    "hypothesis = x_train.matmul(W) + b  #matmul로 한번에 계산 / x값이 바뀌어도 코드 수정 x, 속도빠름  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.mean((hypothesis - y_train)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent with torch.optim\n",
    "\n",
    "### optimizer 설정 optimizer = torch.optim.SGD([W,b],lr=1e-5)\n",
    "### optimizer 사용법   -> 3줄 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "# FUll Code with torch.optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 전"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73,90,75],\n",
    "                             [93,88,93],\n",
    "                             [89,91,90],\n",
    "                             [96,98,100],\n",
    "                             [73,66,70]])\n",
    "y_train = torch.FloatTensor([[152],[185],[180],[196],[142]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros((3,1),requires_grad=True)\n",
    "b = torch.zeros(1,requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([W,b],lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 -> simple과 동일함 => pytorch의 확장성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/30 hypothesis: tensor([0., 0., 0., 0., 0.]), Cost: 29661.800781\n",
      "Epoch    1/30 hypothesis: tensor([70.7410, 81.3747, 80.2056, 87.3352, 62.0618]), Cost: 9099.662109\n",
      "Epoch    2/30 hypothesis: tensor([109.9031, 126.4273, 124.6099, 135.6869,  96.4222]), Cost: 2797.196045\n",
      "Epoch    3/30 hypothesis: tensor([131.5821, 151.3709, 149.1935, 162.4561, 115.4464]), Cost: 865.427612\n",
      "Epoch    4/30 hypothesis: tensor([143.5819, 165.1815, 162.8037, 177.2766, 125.9798]), Cost: 273.312836\n",
      "Epoch    5/30 hypothesis: tensor([150.2230, 172.8285, 170.3387, 185.4818, 131.8126]), Cost: 91.811943\n",
      "Epoch    6/30 hypothesis: tensor([153.8974, 177.0631, 174.5103, 190.0247, 135.0429]), Cost: 36.167305\n",
      "Epoch    7/30 hypothesis: tensor([155.9293, 179.4086, 176.8198, 192.5399, 136.8324]), Cost: 19.098640\n",
      "Epoch    8/30 hypothesis: tensor([157.0518, 180.7081, 178.0984, 193.9326, 137.8242]), Cost: 13.853747\n",
      "Epoch    9/30 hypothesis: tensor([157.6710, 181.4286, 178.8063, 194.7039, 138.3744]), Cost: 12.232909\n",
      "Epoch   10/30 hypothesis: tensor([158.0114, 181.8285, 179.1982, 195.1310, 138.6801]), Cost: 11.722992\n",
      "Epoch   11/30 hypothesis: tensor([158.1975, 182.0510, 179.4151, 195.3677, 138.8505]), Cost: 11.553559\n",
      "Epoch   12/30 hypothesis: tensor([158.2982, 182.1751, 179.5352, 195.4989, 138.9459]), Cost: 11.488516\n",
      "Epoch   13/30 hypothesis: tensor([158.3517, 182.2449, 179.6016, 195.5717, 138.9998]), Cost: 11.455512\n",
      "Epoch   14/30 hypothesis: tensor([158.3789, 182.2845, 179.6384, 195.6123, 139.0307]), Cost: 11.432337\n",
      "Epoch   15/30 hypothesis: tensor([158.3916, 182.3075, 179.6588, 195.6349, 139.0490]), Cost: 11.412190\n",
      "Epoch   16/30 hypothesis: tensor([158.3963, 182.3212, 179.6700, 195.6475, 139.0601]), Cost: 11.393023\n",
      "Epoch   17/30 hypothesis: tensor([158.3966, 182.3298, 179.6762, 195.6548, 139.0674]), Cost: 11.374138\n",
      "Epoch   18/30 hypothesis: tensor([158.3945, 182.3356, 179.6796, 195.6589, 139.0726]), Cost: 11.355349\n",
      "Epoch   19/30 hypothesis: tensor([158.3909, 182.3399, 179.6815, 195.6614, 139.0765]), Cost: 11.336627\n",
      "Epoch   20/30 hypothesis: tensor([158.3866, 182.3432, 179.6825, 195.6630, 139.0798]), Cost: 11.317984\n",
      "Epoch   21/30 hypothesis: tensor([158.3819, 182.3461, 179.6830, 195.6640, 139.0827]), Cost: 11.299337\n",
      "Epoch   22/30 hypothesis: tensor([158.3770, 182.3487, 179.6833, 195.6648, 139.0854]), Cost: 11.280741\n",
      "Epoch   23/30 hypothesis: tensor([158.3720, 182.3512, 179.6834, 195.6654, 139.0879]), Cost: 11.262140\n",
      "Epoch   24/30 hypothesis: tensor([158.3669, 182.3535, 179.6835, 195.6659, 139.0904]), Cost: 11.243642\n",
      "Epoch   25/30 hypothesis: tensor([158.3617, 182.3558, 179.6835, 195.6664, 139.0929]), Cost: 11.225100\n",
      "Epoch   26/30 hypothesis: tensor([158.3566, 182.3581, 179.6835, 195.6668, 139.0954]), Cost: 11.206633\n",
      "Epoch   27/30 hypothesis: tensor([158.3514, 182.3604, 179.6835, 195.6673, 139.0978]), Cost: 11.188217\n",
      "Epoch   28/30 hypothesis: tensor([158.3462, 182.3627, 179.6835, 195.6677, 139.1003]), Cost: 11.169756\n",
      "Epoch   29/30 hypothesis: tensor([158.3410, 182.3650, 179.6834, 195.6681, 139.1027]), Cost: 11.151373\n",
      "Epoch   30/30 hypothesis: tensor([158.3359, 182.3672, 179.6833, 195.6685, 139.1051]), Cost: 11.133057\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 30\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    #H(x) 계산\n",
    "    hypothesis = x_train.matmul(W) + b \n",
    "    \n",
    "    #cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train)**2)\n",
    "    \n",
    "    #cost로 H(x) 계산\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch {:4d}/{} hypothesis: {}, Cost: {:.6f}'.format(\n",
    "        epoch,nb_epochs,hypothesis.squeeze().detach(),cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " W = torch.zeros((3,1),requires_grad=True)   \n",
    " b = torch.zeros(1,requires_grad=True)   \n",
    " H(x) 계산   \n",
    "  -> hypothesis = x_train.matmul(W) + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-126b26626151>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mhypothesis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "hypothesis = model(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#F.mse_loss\n",
    "\n",
    "#cost 계산\n",
    "#    cost = torch.mean((hypothesis - y_train)**2)\n",
    "\n",
    "\n",
    "#import torch.nn.functional as F\n",
    "\n",
    "#cost = F.mse_loss(prediction, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Full code with torch.optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 전\n",
    "\n",
    "#데이터\n",
    "x_train = torch.FloatTensor([[73,80,75],\n",
    "                             [93,88,93],\n",
    "                             [89,91,90],\n",
    "                             [96,98,100],\n",
    "                             [73,66,70]])\n",
    "y_train = torch.FloatTensor([[152],[185],[180],[196],[142]])\n",
    "\n",
    "\n",
    "#모델 초기화\n",
    "#W = torch.zeros((3,1),requires_grad=True)\n",
    "#b = torch.zeros(1,requires_grad=True)\n",
    "\n",
    "model = MultivariateLinearRegressionModel()\n",
    "\n",
    "#optimizer 설정\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
